---
title: "ASM - LASSO Spam"
author: "Sergi Carol, Laura Cebollero, Alex Rodriguez"
date: "21st November, 2018"
output: pdf_document
---

```{r setup, include=FALSE}
library("data.table")
library("knitr")
library("glmnet")
library("caret")
library("pROC")
library("ROCR")    
```

# Introduction



# Reading the data
```{r}
source("spam.R")
```


# Preparing the data

```{r}
totalNumObs = nrow(spam)

mail.spam = spam[which(spam$spam.01 == 1), ]
mail.non.spam = spam[which(spam$spam.01 == 0), ]


## Proportions of Spam
train.prop.spam = 2*nrow(mail.spam)/3

spam.training = mail.spam[1:train.prop.spam,]
spam.val = mail.spam[train.prop.spam:nrow(mail.spam),]


## Proportions non-spam
train.prop.no.spam = 2*nrow(mail.non.spam)/3

non.spam.training = mail.non.spam[1:train.prop.no.spam,]
non.spam.val = mail.non.spam[train.prop.no.spam:nrow(mail.non.spam),]


## Merging

train.set = rbind(spam.training, non.spam.training)
val.set = rbind(spam.val, non.spam.val)


## Scaling and centering
train.set.spam <- train.set[, 58]
sc.train.set <- scale(train.set[, 1:57])
sc.train.set <- data.frame(sc.train.set, "spam.01" = as.factor(train.set.spam))


mat.train.set <- as.matrix(train.set)
mean.train.set <- mean(mat.train.set)
sd.train.set <- sd(mat.train.set)

# Scale validation set
sc.val.set <- (val.set[, 1:57] - mean.train.set)/sd.train.set
sc.val.set <- as.data.frame(sc.val.set)
colnames(sc.val.set) <- names(sc.train.set[, 1:57])
true.val.spam <- val.set$spam.01

```

# Classification rules

## Logistic regression fitted by maximum likelihood.

```{r}
log.reg.fit <- glm(spam.01 ~ ., data=sc.train.set, family = binomial(link = "logit"))
y.pred <- predict(log.reg.fit, sc.val.set, type="response")
y.pred <- ifelse(y.pred >= 0.5,1,0)

head(y.pred)

summary(y.pred)
plot(log.reg.fit)

# Confusion matrix
cm = confusionMatrix(data = as.factor(y.pred), as.factor(true.val.spam))
cm$table
cm$byClass
cm$overall

auc(true.val.spam, y.pred)

pred <- prediction(y.pred, true.val.spam)    
perf <- performance(pred, measure = "tpr", x.measure = "fpr")     
plot(perf, col=rainbow(7), main="ROC curve", xlab="Specificity", 
     ylab="Sensitivity")    
abline(0, 1) #add a 45 degree line
```


## Logistic regression fitted by LASSO

## K-NN binary regression


<!-- For each rule, state the missclassifcation rate and so on.

Optional:  Compute the confussion table + ROC + AUC -->

