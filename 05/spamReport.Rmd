---
title: "ASM - LASSO Spam"
author: "Sergi Carol, Laura Cebollero, Alex Rodriguez"
date: "21st November, 2018"
output: pdf_document
---

```{r setup, include=FALSE}
library("data.table")
library("knitr")
library("glmnet")
library("caret")
library("ROCR")    
```

# Introduction



# Reading the data
```{r}
source("spam.R")
```


# Preparing the data

```{r}
mail.spam = spam[which(spam$spam.01 == 1), ]
mail.non.spam = spam[which(spam$spam.01 == 0), ]


## Proportions of Spam
train.prop.spam = 2*nrow(mail.spam)/3

spam.training = mail.spam[1:train.prop.spam,]
spam.val = mail.spam[train.prop.spam:nrow(mail.spam),]


## Proportions non-spam
train.prop.no.spam = 2*nrow(mail.non.spam)/3

non.spam.training = mail.non.spam[1:train.prop.no.spam,]
non.spam.val = mail.non.spam[train.prop.no.spam:nrow(mail.non.spam),]

## Merging

train.set = rbind(spam.training, non.spam.training)
val.set = rbind(spam.val, non.spam.val)
train.set$spam.01 <-  as.factor(train.set$spam.01)
val.set$spam.01 <-  as.factor(val.set$spam.01)

x.train <- as.matrix(train.set[, 1:57])
y.train <- as.factor(train.set$spam.01)

x.val <- as.matrix(val.set[, 1:57])
y.val <- as.factor(val.set$spam.01)

table(y.val)
```

# Classification rules

With the different sets of data created we can now procede to the creation of the differnet models, we will start using the standar _glm_ model. The model is pretty simple, we will try to predict the value of _spam.01_, it is important to note that we are setting the parameter __family__ to _binomial_ since this is the distribution of our response. We can also see how the method produces an error, this is normal since it simply says that the covariates are nearly perfect predictors.

## Logistic regression fitted by maximum likelihood.

```{r}

m1 <- glm(spam.01 ~ .,data=train.set, family=binomial)
## you don't need to worry about this warning.  
## It says that some covariates are nearly perfect predictors.
plot(m1$fit~train.set$spam.01, 
     xlab="", ylab=c("fitted probability of spam"), 
     col=c("navy","red"))
y.pred <- predict(m1, as.data.frame(x.val), type="response")
summary(y.pred)

y_pred_num <- ifelse(y.pred < 0.5, 0, 1) # Convert values to 0 and 1
table(y_pred_num)

cm = confusionMatrix(data = as.factor(y_pred_num), as.factor(val.set$spam.01))
cm$table
cm$byClass
cm$overall

#auc(val.set$spam.01, y.pred)

pred <- prediction(y.pred, val.set$spam.01)    
perf <- performance(pred, measure = "tpr", x.measure = "fpr")     
plot(perf, col=rainbow(7), main="ROC curve", xlab="Specificity", 
     ylab="Sensitivity")    
abline(0, 1) #add a 45 degree line
```

There a few thing we want to point out from this code, the first one is that since the prediction model does not return 0s or 1s (as expected), we must convert these values to 0s and 1s ourselves, for this case any predicted value equal or higher than 0.5 will become a 1 and a 0 if lower.

Once we have the values converted to the appropiate values we can check how good our model is. As we can see we can obtain a pretty good model with a total of _0.865_ accuracy, moreover it is more interesting to look at the rate of badily classified non spam emails, since it is quite important that it is as low as possible, due to not wanting to classify normal emails as spam, which is more important than classifing spammy emails as normal ones. From the table we can clearly see how __COM ES CALCULAVA AIXO?__.

We have also calculated the ROC curve, which gives a general idea of how good the model is. It does indeed show that we have a pretty good model.

## Logistic regression fitted by LASSO

```{r}
m2 <- cv.glmnet(x.train, y.train, alpha=1, family = "binomial", standardize=FALSE, nfolds=10)
plot(m2)
#m2 <- glmnet(x.train, y.train, alpha=1, family = "binomial", standardize=FALSE)
y.pred <- predict(m2, x.val, type="response")
y_pred_num <- ifelse(y.pred < 0.5, 0, 1)

cm = confusionMatrix(data = as.factor(y_pred_num), as.factor(val.set$spam.01))
cm$table
cm$byClass
cm$overall
```

## K-NN binary regression


<!-- For each rule, state the missclassifcation rate and so on.

Optional:  Compute the confussion table + ROC + AUC -->

