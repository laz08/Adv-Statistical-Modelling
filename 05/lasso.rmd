---
title: "Lab2"
author: "Sergi Carol Laura Cebollero Alex Rodriguez"
date: "November 15, 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
library(glmnet)
library(knitr)
data(Boston) # TODO: Check for the Boston Corrected dataset (where to download it?)
source("all_functions.R")
```


```{r}
set.seed(123)

lambda.max <- 1e5
n.lambdas <- 74
lambda.v <- exp(seq(0,log(lambda.max+1),length=n.lambdas))-1
## Data exploration
summary(Boston)

Y <- scale( Boston$medv, center=TRUE, scale=FALSE)
X <- scale( as.matrix(Boston[,1:13]), center=TRUE, scale=TRUE)
n <- dim(X)[1]
p <- dim(X)[2]
XtX <- t(X)%*%X 
d2 <- eigen(XtX,symmetric = TRUE, only.values = TRUE)$values
df.v <- numeric(n.lambdas)
for (l in 1:n.lambdas){
  lambda <- lambda.v[l]
  df.v[l] <- sum(d2/(d2+lambda)) 
}

```

### 1  For the Boston House-price corrected dataset use Lasso estimation (in glmnet) to fit the regression model where the response is CMEDV (the corrected version of MEDV) and the explanatory variables are the remaining 13 variables in the previous list. Try to provide an interpretation to the estimated model.

We want to note that we did not find the mentioned dataset in the raco, and as such we have used the one in the package _MASS_, which does not have the corrected version of MEDV, and as such we will be using MEDV as our target variable.

```{r}
m1.lasso <- glmnet(X, Y, lambda= lambda.v)
summary(m1.lasso)
plot(m1.lasso, xvar="lambda")
plot(log(m1.lasso$lambda), m1.lasso$dev.ratio, type='b')
```

Caldria computar el lambda minim + sd per saber quin valor agafar


### 2 Use glmnet to fit the previous model using ridge regression. Compare the 10-fold cross validation results from function cv.glmnet with those you obtained in the previous practice with your own functions.

```{r}
m2.rr <- glmnet(X, Y, alpha=0)
summary(m2.rr)
plot(m2.rr,  xvar="lambda")
plot(log(m2.rr$lambda), m2.rr$dev.ratio, type='b')
# Same as up
```
As expected we can see how the error goes down the higer the value of the lamdas.

In order to compare the two models ww will use the same lambdas that we have generated and feed them two both methods, thus ensuring that the results are not tricked by using differnet values of lambdas, we will also set the __standardize__ flag to false since our data is already standardized. 
```{r}
m3.rr <- cv.glmnet(X, Y, nfolds=10, lambda =  lambda.v, standardize=FALSE, intercept=FALSE, alpha=0)
plot(m3.rr)
abline(v=log(m3.rr$lambda.min),col=2,lty=2)
abline(v=log(m3.rr$lambda.1se),col=2,lty=2)
cvm <- rev(m3.rr$cvm)

m4.rr <-  MSPEkfold(X, Y, 10, n.lambdas, lambda.v, n)
points(log(lambda.v), m4.rr, col=5)
legend("bottomright", c("glmnet error", "k.fold error"), col=c(2,5), lty=c(2,2), lwd=c(1,1)) # FIX

min.lambda <- data.frame("K.fold" = lambda.v[which.min(m4.rr)], "glmnet" = m3.rr$lambda.min)
min.df <- data.frame("K.fold" = df.v[which.min(m4.rr)],"glmnet" =df.v[which(lambda.v == m3.rr$lambda.min)])
result <- rbind(min.df, min.lambda)
row.names(result) <- c("df", "lambda")
kable(result)
```

Interestingly we see how the values differ from our method to the one implemented by __glmnet__, most noticiabely the value of the optimal lambda is increased by more than 4 units, yet the value of the degrees of freedom remains similar. We are not sure if our model is wrongly implemented or it simply that the glmnet method is doing things differnetly from what we did. Yet if we take a look at the plot which compares the Mean Square error to with the values of the lambdas we can see how both models seem to follow the same shape, but our model starts the curve later on, meaning that it does not start increasing the error until higher values of $\lambda$

```{r}
lambda.glm <- m3.rr$lambda
df.v.g <- numeric(n.lambdas)
for (l in 1:n.lambdas){
  lambda <- lambda.glm[l]
  df.v.g[l] <- sum(d2/(d2+lambda)) 
}
plot(df.v, cvm, col=1,pch=19,cex=.75)
points(df.v, m4.rr,col=8,pch=19,cex=.75)
``` 

In this plot we are comparing the value sof the degrees of freedom against the mean square error, we can clearly see how both methods start and finish in the same values, which is expected, yet there is a big differnece in the values between, our method lowers the error faster with lower values of _df_, yet it seems to stagnate with higher value of the degrees of freedom. Meanwhile the glmnet method follow more of a curve torwards lower error but higher degrees of freedom. It seems that our method is better if we want to use lower lambdas since it provides less error.
<!-- Enserio wtf esta passant aqui-->

