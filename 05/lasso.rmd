---
title: "ASM - LASSO"
author: "Sergi Carol, Laura Cebollero, Alex Rodriguez"
date: "November 15, 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
library(glmnet)
library(knitr)
data(Boston) # TODO: Check for the Boston Corrected dataset (where to download it?)
source("all_functions.R")

wd = getwd()
if(grepl("nora", wd)) {
    setwd("~/Documents/18-19/ASM/HW/05")
} else {
    ## Put working path for Sergi and Alex
}
rm(wd)

```

\noindent\fbox{%
    \parbox{\textwidth}{%
      
 \textbf{$\rightarrow$} First of all, we want to note that we did \textbf{not find} the  mentioned corrected dataset in \texttt{El Raco}, and as such we have used the one in the package MASS, which does not have the corrected version of MEDV. 
 
 Because of this, we will be using \textbf{MEDV} as our \textbf{target variable}.

    }%
}


# 1. Lasso for the Boston Housing Area
```{r results=FALSE}
set.seed(123)

lambda.max <- 1e5
n.lambdas <- 74
lambda.v <- exp(seq(0,log(lambda.max+1),length=n.lambdas))-1
## Data exploration
summary(Boston)

# Prepare data
Y <- scale( Boston$medv, center=TRUE, scale=FALSE)
X <- scale( as.matrix(Boston[,1:13]), center=TRUE, scale=TRUE)
n <- dim(X)[1]
p <- dim(X)[2]
XtX <- t(X)%*%X 
d2 <- eigen(XtX,symmetric = TRUE, only.values = TRUE)$values
df.v <- numeric(n.lambdas)
for (l in 1:n.lambdas){
  lambda <- lambda.v[l]
  df.v[l] <- sum(d2/(d2+lambda)) 
}
```

## 1.1.  For the Boston House-price corrected dataset use Lasso estimation (in glmnet) to fit the regression model where the response is CMEDV (the corrected version of MEDV) and the explanatory variables are the remaining 13 variables in the previous list. Try to provide an interpretation to the estimated model.


```{r}
m1.lasso <- glmnet(X, Y, lambda=lambda.v)
summary(m1.lasso)
minLambda = min(m1.lasso$lambda + m1.lasso$dev)

plot(m1.lasso, xvar="lambda")
plot(log(m1.lasso$lambda), m1.lasso$dev.ratio, type='b')
abline(v=minLambda,col=2,lty=2)
```


### Interpretation


In the plot above, each colored line is a different coefficient value in our model.

We can see that when lambda is small we use all the variables, but as lambda increases, these variables are not used anymore. 

Or in other words, less variables are allowed because we are increasing lambda, thus we are having a greater penalization on the number of variables used.

On the second plot....

## 1.2. Use glmnet to fit the previous model using ridge regression. Compare the 10-fold cross validation results from function cv.glmnet with those you obtained in the previous practice with your own functions.

```{r}
m2.rr <- glmnet(X, Y, alpha=0)
summary(m2.rr)
plot(m2.rr,  xvar="lambda")
plot(log(m2.rr$lambda), m2.rr$dev.ratio, type='b')
# Same as up
```
As expected we can see how the error goes down the higher the value of the lamdas.

In order to compare the two models we will use the same lambdas that we have generated and feed them to both methods, thus ensuring that the results are not tricked by using differnet values of lambdas.

We will also set the __standardize__ flag to false since our data is already standardized as seen in the first block of code. Opting to use the original that without centering and standarizing it could have also been an option, too.

We have tried sending to glmnet the data without centering it ourselves and letting the function standardize it itself, but the results have been the same.

```{r eval=FALSE, echo=FALSE, include=FALSE}
Y2 <- scale(Boston$medv, center=TRUE, scale=FALSE)
X2 <- scale(as.matrix(Boston[,1:13]), center=TRUE, scale=FALSE)
n <- dim(X2)[1]
p <- dim(X2)[2]
XtX2 <- t(X2)%*%X2 
d22 <- eigen(XtX2,symmetric = TRUE, only.values = TRUE)$values


m3.rr <- cv.glmnet(X2, Y2, nfolds=10, lambda =  lambda.v, standardize=TRUE, intercept=FALSE, alpha=0)

```


```{r}
m3.rr <- cv.glmnet(X, Y, nfolds=10, lambda =  lambda.v, standardize=FALSE, intercept=FALSE, alpha=0)
plot(m3.rr, main="Lambdas")
abline(v=log(m3.rr$lambda.min),col=2,lty=2)
abline(v=log(m3.rr$lambda.1se),col=2,lty=2)
cvm <- rev(m3.rr$cvm)

m4.rr <-  MSPEkfold(X, Y, 10, n.lambdas, lambda.v, n)
points(log(lambda.v), m4.rr, col=5)
legend("bottomright", c("glmnet error", "k.fold error"), col=c(2,5), lty=c(2,2), lwd=c(1,1)) # FIX

min.lambda <- data.frame("K.fold" = lambda.v[which.min(m4.rr)], "glmnet" = m3.rr$lambda.min)
min.df <- data.frame("K.fold" = df.v[which.min(m4.rr)],"glmnet" =df.v[which(lambda.v == m3.rr$lambda.min)])
result <- rbind(min.df, min.lambda)
row.names(result) <- c("df", "lambda")

kable(result)
```

Interestingly enough, we see how the values differ from our method to the one implemented by __glmnet__. Taking a look at the table, the most noticeable thing is that the optimal lambda is increased by more than 4 units, yet the value of the degrees of freedom remains almost the same. 

We are not sure if our model is wrongly implemented or it is simply that the glmnet method is doing things differently from what we did in our implementation. 

Yet if we take a look at the plot which compares the Mean Square error to with the values of the lambdas we can see how both models seem to follow the same shape.

However, our model starts the curve later on (around 4 units), meaning that the Mean Squared Error does not start increasing until reaching higher values of $\lambda$.

```{r}
lambda.glm <- m3.rr$lambda
df.v.g <- numeric(n.lambdas)
for (l in 1:n.lambdas){
  lambda <- lambda.glm[l]
  df.v.g[l] <- sum(d2/(d2+lambda)) 
}

plot(df.v, cvm, col=1,pch=19,cex=.75, ylab="MSE", xlab="Degrees of freedom", main="Comparison of MSE models")
points(df.v, m4.rr,col=8,pch=19,cex=.75)

legend("topright",
       c("glmnet","kfold"),
       pch=c(19, 19),
       col=c(8, 1)
       )


``` 

In this plot we are comparing the values of the degrees of freedom against the mean square error.

We can clearly see how both methods start and finish in the same values, which is expected.

Yet there is a big difference in the values between: our method lowers the error slower as more degrees of freedom are reached (so less variables are used).

Meanwhile the glmnet method follows more of a curve on the opposite sides towards lower error. It seems to stagnate when reaching higher degrees of freedom.

Assuming our method is correct, it seems that our implementation of k-fold is worse, since unless we reach 13 degrees of freedom, the MSE does not lower below 40.

The glmnet function proves to be getting less error around 4/6 degrees of freedom, so this would be our preferred method.

<!-- 
    Sergi: Enserio que esta passant aqui?
    Laura: Jo diria que la nostra impl. no esta be. Pero com no tenim la correccio....
    
-->
## Final discussion

Our conclussion is that maybe our method has not been properly implemented, since we are having the same issues when passing the data untouched to glmnet and telling it to standardize it itself.

This tells us that the root of the discrepancies of the results emerge probably from a bad implementation from our side of the k-Fold function. However, we have rechecked it and we cannot pinpoint our fault in the implementation.

Thus, we will remain waiting for the correction of the first lab to correct this one.